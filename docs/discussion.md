---
layout: page
title: Discussion
permalink: /discussion/
---

Our results indicate no major increase in win rate using Epistemic or basic Logic agents against Random agents. We suspect this might be due to the nature of the Old Maid game, which originated as a gambling game, since luck is a major factor in picking the most desirable cards from your opponents. As the cards are shuffled, there is a considerable amount of luck involved, even with informed or logically grounded decisions. Moreover, picking the correct opponent is relatively unimportant with just two opponents (50% chance), compared to choosing the correct opponent in a game of, for example, 10 players. Thus, even though there is strategy involved, the strategy might not yield better results when factoring in all luck aspects of the game that are still present. All that said, playing Epistemic agents against Logic agents showed that adding epistemic knowledge slightly decreases performance compared to basic logical knowledge.

Secondly, the results of the number of lost games per agent show a slight skew towards the second agent losing more often in the first two conditions. The importance of the order of the agents was minimized by randomly picking the starting the starting player and continuing the game in clockwise order. However, for reasons that are unknown to us at this point, the second player (a Random agent in the first two conditions) loses more games than the Logic, Epistemic, and the third player (also a Random agent in the first two conditions).

Finally, our research question was whether adding epistemic announcements carries useful information for an agent to perform better in the game of Old Maid. We concluded from our experiments that basic logical knowledge and epistemic knowledge does not lead to better performance in the Old Maid game. In contrast, we also observed a slightly worse performance of playing with an Epistemic agent against two basic Logic agents. Therefore, epistemic announcements do not seem to lead to better performance in the Old Maid game when playing with three players.

# Limitations & Future Work
We acknowledge that some experiments were left out, which was done due to limited time. Playing more agents against each other to reduce the luck aspect of choosing an opponent to draw from would have been more favourable. However, computing all possible worlds for more agents or more cards is a computationally expensive task as its computational load scales exponentially with each added card or player. Further, we would have liked to perform all types of experiments with the same type of agents playing against each other and measure whether the game length increased when agents were playing more carefully, picking from players with more cards as much as possible. This can all be left in a future research into this topic, where an extensive review can be performed with the code that is available from this project.
Finally, in our current implementation we set the strategy to something we think is reasonable, but may not necessarily be the optimal strategy. It might be interesting to examine whether these models could be used to assist, for example, a Reinforcement Learning agent learn an optimal policy in a Partially Observable Markov Decision Process (POMDP).